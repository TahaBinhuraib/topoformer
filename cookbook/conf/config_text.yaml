model:
  hidden_size: 400
  num_hidden_layers: 1
  num_attention_heads: 1
  forward_expansion: 4
  hidden_dropout_prob: 0.0
  attention_probs_dropout_prob: 0.0
  qkv_bias: true
  max_length: 256
  dropout: 0.1
  sr: 0.3
  sq: 0.1
  learned_spatial_querying: False
  local_querying: False
  mask_type: "circular"
  pooling_mechanism: "AVERAGE"
  relu: False
  model_version: "v2"
  

params:
  wandb_name: "topoformer"
  batch_size: 256
  epochs: 20
  dataset_name: "imdb"
  seed: 42
  lr: 1e-3